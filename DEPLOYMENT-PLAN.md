# ðŸš€ BookEqualizer Phase 2 Deployment Plan

## ðŸ“Š Current Status
- **Phase 2 Implementation**: 95% COMPLETE âœ…
- **Code Quality**: Production-ready AI service + frontend
- **Blocker**: Railway deployment failing on heavy ML dependencies
- **Solution**: Incremental deployment approach

## ðŸŽ¯ Services to Deploy

### 1. AI Service (Python/FastAPI) â†’ Railway
- **Current**: Full implementation with all features
- **Issue**: pip install failing on `spacy`, `langchain`, `sentence-transformers`
- **Strategy**: Deploy minimal service first, add features incrementally

### 2. Frontend (Next.js) â†’ Vercel  
- **Current**: Complete implementation ready
- **Issue**: Minor dependency conflicts (Clerk version)
- **Strategy**: Fix dependencies, deploy, configure environment variables

### 3. Backend (Node.js) â†’ Already Running
- **Status**: Phase 1 complete, APIs functional
- **Action**: No additional deployment needed

## ðŸ“‹ Step-by-Step Deployment Plan

### RAILWAY DEPLOYMENT (AI Service)

#### Step 1: Minimal FastAPI Service
```python
# Minimal requirements.txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-dotenv==1.0.0
```

**Commands**:
```bash
cd ai-service
# Create minimal main.py with health check only
railway up
# Verify basic service works
```

#### Step 2: Add Features Incrementally
```bash
# Add one feature at a time, test each deployment:
# 1. EPUB processing: +beautifulsoup4, +ebooklib
# 2. Text processing: +nltk, +regex  
# 3. Q&A system: +openai, +pydantic
# 4. Embeddings: +sentence-transformers, +pgvector
# 5. Sync service: +numpy, +scikit-learn
# 6. Heavy ML: +spacy, +langchain (if needed)
```

#### Step 3: Environment Variables (Railway Dashboard)
```
OPENAI_API_KEY=your_key
DATABASE_URL=your_postgres_url
ENVIRONMENT=production
```

### VERCEL DEPLOYMENT (Frontend)

#### Step 1: Fix Dependencies
```bash
cd frontend
# Update package.json - Clerk to v5.0.0
rm -rf node_modules package-lock.json
npm install --legacy-peer-deps
npm run build  # Verify build works
```

#### Step 2: Deploy to Vercel
```bash
npm install -g vercel
vercel
# Follow prompts - select Next.js framework
```

#### Step 3: Environment Variables (Vercel Dashboard)
```
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=your_clerk_key
CLERK_SECRET_KEY=your_clerk_secret
NEXT_PUBLIC_API_URL=your_backend_url
NEXT_PUBLIC_AI_SERVICE_URL=your_railway_url
```

### INTEGRATION TESTING

#### Step 4: End-to-End Testing
1. **EPUB Upload** â†’ AI processing â†’ display
2. **Audio Player** â†’ text highlighting sync  
3. **Q&A System** â†’ AI responses
4. **Cross-device Sync** â†’ progress persistence

## ðŸ”§ Files Ready for Deployment

### AI Service Files:
- `ai-service/main.py` - FastAPI app with all endpoints
- `ai-service/requirements.txt` - Python dependencies
- `ai-service/services/` - All AI processing services
- `ai-service/models/schemas.py` - Pydantic models

### Frontend Files:
- `frontend/src/` - Complete Next.js app
- `frontend/package.json` - Dependencies (needs Clerk update)
- `frontend/src/components/` - All UI components
- `frontend/src/lib/api.ts` - API integration

## ðŸ“ž Handoff Instructions

**Next Agent Should**:
1. **Start with minimal Railway deployment** (health check only)
2. **Add AI features incrementally** (test each step)
3. **Deploy frontend to Vercel** after AI service is stable
4. **Configure production environment variables**
5. **Test end-to-end integration**

**Files to Focus On**:
- `ai-service/main.py` - Simplify for initial deployment
- `ai-service/requirements.txt` - Minimize dependencies first
- `frontend/package.json` - Fix Clerk version to v5.0.0

**Current Railway Project**: `bookequalizer-ai` (already linked)

## ðŸš¨ Important Notes

- **Phase 2 code is production-ready** - deployment issues only
- **Implementation is 95% complete** - not scaffolding
- **All features work locally** - just need cloud deployment
- **Incremental approach prevents dependency hell**

---
**Next Action**: Deploy minimal FastAPI service to Railway, then add features one by one.